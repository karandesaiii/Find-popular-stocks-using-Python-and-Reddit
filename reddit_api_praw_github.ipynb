{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e45b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import praw, pandas as pd\n",
    "from time import time\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2bf2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First you need your reddit API credentials\n",
    "# follow this blog post to get them: https://www.jcchouinard.com/get-reddit-api-credentials-with-praw/\n",
    "\n",
    "# create praw reddit instance - \n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"Your-client-id\",\n",
    "    client_secret=\"Your-client-secret\",\n",
    "    password=\"Your-reddit-account-password\",\n",
    "    user_agent=\"test script\",\n",
    "    username=\"Your-reddit-username\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d16fa01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Should print your reddit username\n",
    "print(reddit.user.me())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bd6c0b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter URL of today's Daily Discussion of the subreddit wallstreetbets: https://www.reddit.com/r/wallstreetbets/comments/qnjay6/weekend_discussion_thread_for_the_weekend_of/\n",
      "Enter 600 to get best 60-70% comments(takes 10 minutes to run) and 1200 for top 80+% comments(takes 15-20 minutes to run) : 600\n",
      "submission created\n",
      "Extracting comments...\n",
      "replace more limit set as 600\n",
      "\n",
      "Number of comments in the thread: 8355\n",
      "8355 comments extracted\n",
      "\n",
      "time taken 8 minutes\n"
     ]
    }
   ],
   "source": [
    "#Extracting comments in a subreddit discussion sorted by reddit's \"Best\" filter \n",
    "\n",
    "#Enter URL of a discussion thread\n",
    "url=input(\"Enter URL of today's Daily Discussion of the subreddit wallstreetbets: \")\n",
    "#replace limit\n",
    "\n",
    "repLimit=input(\"Enter 600 to get best 60-70% comments(takes 10 minutes to run) and 1200 for top 80+% comments(takes 15-20 minutes to run) : \")\n",
    "###########################\n",
    "\n",
    "st=time()\n",
    "submission = reddit.submission(url=url)\n",
    "print('submission created')\n",
    "print(\"Extracting comments...\")\n",
    "submission.comments.replace_more(limit=int(repLimit))\n",
    "print('replace more limit set as',repLimit)\n",
    "print()\n",
    "print(\"Number of comments in the thread:\",len(submission.comments.list()))\n",
    "\n",
    "#appending comments\n",
    "submissionList = []\n",
    "for comment in submission.comments.list():\n",
    "#     print(comment)\n",
    "#     print(comment.body)\n",
    "    submissionList.append(comment)\n",
    "print(len(submissionList),'comments extracted')\n",
    "\n",
    "print()\n",
    "print('time taken',round((time()-st)/60),'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b02848ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many hours behind do you wanna look? :12\n",
      "2564 comments in the last 12 hours\n"
     ]
    }
   ],
   "source": [
    "# Enter number of hours to look back for popular tickers\n",
    "hoursBack=input(\"How many hours behind do you wanna look? :\")\n",
    "\n",
    "current_time=datetime.now()\n",
    "\n",
    "fewHourComments=[]\n",
    "fewhoursback=current_time-timedelta(hours=int(hoursBack))\n",
    "for comment in submissionList:\n",
    "    if datetime.fromtimestamp(comment.created_utc)>=fewhoursback:\n",
    "        fewHourComments.append(comment)\n",
    "print(len(fewHourComments), \"comments in the last \"+hoursBack+\" hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a53969d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy word tokenizer \n",
    "tokenizer = Tokenizer(nlp.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b1ac6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting ticker frequency \n",
    "tickerDict=dict()\n",
    "saver={}\n",
    "for i,x in enumerate(fewHourComments):\n",
    "    \n",
    "    #logic to extract tickers\n",
    "    tickers=list(set([str(tic) for tic in tokenizer(x.body) if (str(tic).isupper() and len(str(tic))<=4 and nlp.vocab[str(tic)].is_stop==False and not(any(k.isdigit() for k in str(tic))))]))\n",
    "    for m in tickers:\n",
    "        if str(x) in tickerDict.keys():\n",
    "            if m not in tickerDict[str(x)]:\n",
    "                tickerDict[str(x)].append(m)\n",
    "        else:\n",
    "            tickerDict[str(x)]=[m]\n",
    "    \n",
    "    \n",
    "    saver[str(x)]=x.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "880b2c38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2564, 6)\n"
     ]
    }
   ],
   "source": [
    "# appending relevant comments data in dataframe for future use\n",
    "comdf=pd.DataFrame()\n",
    "for comment in fewHourComments:\n",
    "\n",
    "    comdf=comdf.append({'author':comment.author,'comment':comment.body,'utc':comment.created_utc,\n",
    "                       'upvotes':comment.score,'url':'reddit.com/'+comment.permalink,\n",
    "                        'replies':comment.replies.__len__()},ignore_index=True)\n",
    "\n",
    "\n",
    "print(comdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b935060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>utc</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>url</th>\n",
       "      <th>replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VisualMod</td>\n",
       "      <td>#Ban Bet Lost\\n\\n/u/_Apache_Helicopter_ (0/1) ...</td>\n",
       "      <td>1.636217e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>reddit.com//r/wallstreetbets/comments/qnjay6/w...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trashcanpandas</td>\n",
       "      <td>I miss being single. sleeping around and meeti...</td>\n",
       "      <td>1.636183e+09</td>\n",
       "      <td>26.0</td>\n",
       "      <td>reddit.com//r/wallstreetbets/comments/qnjay6/w...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnalLeekage</td>\n",
       "      <td>My banbet is over, I'm back bitches.\\n\\n!banbe...</td>\n",
       "      <td>1.636206e+09</td>\n",
       "      <td>30.0</td>\n",
       "      <td>reddit.com//r/wallstreetbets/comments/qnjay6/w...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdPotential6247</td>\n",
       "      <td>my sister's having a baby! im gonna be a dad!</td>\n",
       "      <td>1.636206e+09</td>\n",
       "      <td>18.0</td>\n",
       "      <td>reddit.com//r/wallstreetbets/comments/qnjay6/w...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turd-Lipstick</td>\n",
       "      <td>If I was holding /u/cashflow_ and Remy off a c...</td>\n",
       "      <td>1.636212e+09</td>\n",
       "      <td>20.0</td>\n",
       "      <td>reddit.com//r/wallstreetbets/comments/qnjay6/w...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author                                            comment  \\\n",
       "0        VisualMod  #Ban Bet Lost\\n\\n/u/_Apache_Helicopter_ (0/1) ...   \n",
       "1   trashcanpandas  I miss being single. sleeping around and meeti...   \n",
       "2      AnalLeekage  My banbet is over, I'm back bitches.\\n\\n!banbe...   \n",
       "3  AdPotential6247      my sister's having a baby! im gonna be a dad!   \n",
       "4    Turd-Lipstick  If I was holding /u/cashflow_ and Remy off a c...   \n",
       "\n",
       "            utc  upvotes                                                url  \\\n",
       "0  1.636217e+09      1.0  reddit.com//r/wallstreetbets/comments/qnjay6/w...   \n",
       "1  1.636183e+09     26.0  reddit.com//r/wallstreetbets/comments/qnjay6/w...   \n",
       "2  1.636206e+09     30.0  reddit.com//r/wallstreetbets/comments/qnjay6/w...   \n",
       "3  1.636206e+09     18.0  reddit.com//r/wallstreetbets/comments/qnjay6/w...   \n",
       "4  1.636212e+09     20.0  reddit.com//r/wallstreetbets/comments/qnjay6/w...   \n",
       "\n",
       "   replies  \n",
       "0      0.0  \n",
       "1      6.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      5.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60950aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file name by which you'd like to save:6th_November_weekend_thread_last_12_hours\n",
      "File saved as: 6th_November_weekend_thread_last_12_hours.csv\n"
     ]
    }
   ],
   "source": [
    "#save the dataframe for future use (change name as per requirement)\n",
    "name=input(\"Enter file name by which you'd like to save:\")\n",
    "comdf.to_csv(name+'.csv',index=False)\n",
    "print(\"File saved as:\",name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "685bcce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create frequency dictionary\n",
    "tickerFrequency=dict()\n",
    "for comment in tickerDict.keys():\n",
    "    for tic in tickerDict[comment]:\n",
    "        if tic not in tickerFrequency.keys():\n",
    "            tickerFrequency[tic]=1\n",
    "        else:\n",
    "            tickerFrequency[tic]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "867967e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#storing in dataframe\n",
    "tickerFreqDf=pd.DataFrame(tickerFrequency.items(),columns=['ticker','counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ffb990e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sort by popularity of stock/ticker\n",
    "tickerSorted=tickerFreqDf.sort_values(\"counts\",ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a3135d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add rank\n",
    "tickerSorted['rank']=list(range(1,len(tickerSorted)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb763575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stocks/Tickers sorted by popularity in last 12 hours\n",
      "'counts' column shows the number of unique comments which talked about the stock\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>counts</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPY</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GME</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>CLF</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>*I</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WSB</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PLUG</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EV</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>MA</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CAT</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>OTM</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>AMD</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PTON</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PYPL</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>BLNK</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PTRA</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>WISH</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker  counts  rank\n",
       "1      SPY      34     1\n",
       "16     GME      21     2\n",
       "8     TSLA      15     3\n",
       "52    NVDA      12     4\n",
       "72     CLF      12     5\n",
       "99      *I      10     6\n",
       "7      WSB       9     7\n",
       "18    PLUG       7     8\n",
       "23      EV       7     9\n",
       "220     MA       7    10\n",
       "49     CAT       7    11\n",
       "39       F       5    12\n",
       "96     OTM       5    13\n",
       "71     AMD       5    14\n",
       "27    PTON       4    15\n",
       "20    PYPL       4    16\n",
       "92    BLNK       4    17\n",
       "24    PTRA       4    18\n",
       "168      U       4    19\n",
       "130   WISH       4    20"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stocks/Tickers sorted by frequency/popularity \n",
    "print(\"Stocks/Tickers sorted by popularity in last\",hoursBack,\"hours\")\n",
    "print(\"'counts' column shows the number of unique comments which talked about the stock\")\n",
    "tickerSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6b6bcf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter stock ticker:NVDA\n",
      "\n",
      "#########\n",
      "NVDA’s ceo is a relative of AMDs ceo. That family was probably making computer chips in the feudal era or some shit\n",
      "#########\n",
      "NVDA’s ceo is a relative of AMDs ceo. That family was probably making computer chips in the feudal era or some shit\n",
      "#########\n",
      "What if NET signs a deal with NVDA?\n",
      "\n",
      "I’m pretty high\n",
      "\n",
      "Still be awesome tho\n",
      "\n",
      "Go to sleep, nerd\n",
      "#########\n",
      "NVDA hits all markets - https://forums.evga.com/Notice-of-Stolen-EVGA-GeForce-RTX-30Series-Graphics-Cards-m3490851.aspx\n",
      "#########\n",
      "NVDA hits all markets - https://forums.evga.com/Notice-of-Stolen-EVGA-GeForce-RTX-30Series-Graphics-Cards-m3490851.aspx\n",
      "#########\n",
      "NVDA hits all markets - https://forums.evga.com/Notice-of-Stolen-EVGA-GeForce-RTX-30Series-Graphics-Cards-m3490851.aspx\n",
      "#########\n",
      "Bought AMD and NVDA weeklies before close for the fuck of it. Pls moon.\n",
      "#########\n",
      "Bought AMD and NVDA weeklies before close for the fuck of it. Pls moon.\n",
      "#########\n",
      "Anyone have any thoughts on NVDA for next week\n",
      "#########\n",
      "Next week SPY NVDA RIVN\n",
      "#########\n",
      "Next week SPY NVDA RIVN\n",
      "#########\n",
      "I’m extremely hyped for NVDA earnings\n",
      "#########\n",
      "We think NVDA gonna continue to soar or crash next week? 80% of my port is on soar.\n",
      "#########\n",
      "My entire robinhood portfolio are NVDA calls. Will the infrastructure pump NVDA?\n",
      "#########\n",
      "NVDA is gonna kill it next week\n",
      "#########\n",
      "Every chipmaker is just an arm of the globalist deep state moreso than a real company. However, there are real business interests attached to the stonks for each chipmaker. Seems to me like the business side of NVDA is colluding with the business side of INTC on a master plan to get fucked by AMD, TSMC, AAPL, and probably even lowly QCOM until they go bankrupt so they get an excuse to ask for a bailout and restructure. Also I think it's funny that there's probably some old man out there who pronounces it with hard Rs randomly inserted into the vowels for no reason because of his accent so it comes out like \"Nverdier\" that's just fitting and rolls off the tongue imro\n",
      "#########\n",
      "Every chipmaker is just an arm of the globalist deep state moreso than a real company. However, there are real business interests attached to the stonks for each chipmaker. Seems to me like the business side of NVDA is colluding with the business side of INTC on a master plan to get fucked by AMD, TSMC, AAPL, and probably even lowly QCOM until they go bankrupt so they get an excuse to ask for a bailout and restructure. Also I think it's funny that there's probably some old man out there who pronounces it with hard Rs randomly inserted into the vowels for no reason because of his accent so it comes out like \"Nverdier\" that's just fitting and rolls off the tongue imro\n",
      "#########\n",
      "Buy it. NVDA always goes up (except when it goes down)\n",
      "#########\n",
      "NVDA this past week is an example\n",
      "#########\n",
      "You’ll be fine. NVDA announcing next week at conference about its new subscription based service. Plus their GPUs are essential for mining all that digital gold.\n",
      "#########\n",
      "You’ll be fine. NVDA announcing next week at conference about its new subscription based service. Plus their GPUs are essential for mining all that digital gold.\n"
     ]
    }
   ],
   "source": [
    "#View comments based on the stock ticker\n",
    "stock=input('Enter stock ticker:')\n",
    "print()\n",
    "for comment in saver.values():\n",
    "    for x in tickerSorted.ticker:\n",
    "        if x in comment and stock in comment:\n",
    "            print('#########')\n",
    "            print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit_api",
   "language": "python",
   "name": "reddit_api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
